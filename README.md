# üöÄ Databricks Project: Pipeline Financeiro e Crypto Lakehouse

Este reposit√≥rio documenta a implementa√ß√£o de um pipeline de dados completo na plataforma **Databricks**, utilizando a arquitetura **Lakehouse** e o framework **Lakeflow Declarative Pipelines** (substituto do Delta Live Tables). O foco √© a ingest√£o e modelagem de dados de m√∫ltiplas fontes, incluindo informa√ß√µes de clientes, cota√ß√µes de mercado (financeiro e Bitcoin) e transa√ß√µes, visando a cria√ß√£o de um modelo de dados anal√≠tico robusto e a identifica√ß√£o de m√©tricas de alto valor.

## üéØ Objetivo

O projeto foi constru√≠do para demonstrar a profici√™ncia na **Engenharia de Dados em um ambiente Lakehouse**, focando em:

1.  **Ingest√£o de Dados:** Coletar dados de diferentes APIs e/ou fontes de entrada (clientes, cota√ß√µes, transa√ß√µes).
2.  **Modelagem Dimensional:** Aplicar transforma√ß√µes para criar um modelo de dados (`dim` e `fact`) otimizado para consultas anal√≠ticas e *Business Intelligence* (BI).
3.  **Qualidade de Dados:** Utilizar as *Expectations* do **Lakeflow Declarative Pipelines** para garantir a validade e a confiabilidade dos dados em cada est√°gio.
4.  **Automa√ß√£o e Orquestra√ß√£o:** Implementar o **Lakeflow Declarative Pipelines** para a orquestra√ß√£o declarativa do pipeline, simplificando a manuten√ß√£o e a linhagem dos dados.

## üß± Arquitetura de Refer√™ncia (Medallion Architecture)

O pipeline segue o padr√£o de camadas conhecido como **Medallion Architecture** (Bronze, Silver, Gold), gerenciado dentro do ambiente Databricks, aproveitando o **Delta Lake** para confiabilidade e performance.

$$\text{Sistemas de Origem} \rightarrow \text{Bronze (Raw)} \rightarrow \text{Silver (Refined)} \rightarrow \text{Gold (Curated)}$$

### Camadas do Projeto

| Camada | Descri√ß√£o | Principais Tabelas |
| :--- | :--- | :--- |
| **Bronze** | Dados brutos e n√£o processados. Ingest√£o direta das fontes (APIs/arquivos). | `customers`, `quotation_btc`, `quotation_finance`, `transaction_btc`, `transaction_commodities` |
| **Silver** | Dados limpos, padronizados e enriquecidos. Cria√ß√£o de dimens√µes e fatos intermedi√°rios. | `dim_clientes`, `fact_quotation_assets`, `fact_transaction_assets`, `fact_transaction_revenue` |
| **Gold** | Dados prontos para consumo anal√≠tico. Fatos agregados e **KPIs de neg√≥cio de alto valor**. | `mostvaluableclient` |

### Detalhe da Tabela Gold: `mostvaluableclient`

Esta tabela na camada Gold √© o resultado final da agrega√ß√£o e an√°lise, destinada a identificar os clientes mais valiosos, fornecendo uma vis√£o 360¬∫ para o consumo de BI.

| Coluna | Descri√ß√£o |
| :--- | :--- |
| `customer_sk` | Chave substituta do cliente. |
| `total_transacoes` | Contagem total de transa√ß√µes realizadas. |
| `valor_total` | Valor financeiro total transacionado. |
| `ticket_medio` | Valor m√©dio das transa√ß√µes do cliente. |
| `primeira_transacao` | Data da primeira transa√ß√£o registrada. |
| `ultima_transacao` | Data da √∫ltima transa√ß√£o registrada. |
| `transacoes_ultimos_30_dias` | Contagem de transa√ß√µes nos √∫ltimos 30 dias. |
| `comissao_total` | Total de comiss√£o gerada pelo cliente. |
| `ranking_por_transacoes` | Classifica√ß√£o do cliente com base no volume de transa√ß√µes. |
| `classificacao_cliente` | Classifica√ß√£o de valor (ex: Bronze, Silver, Gold, Platinum). |
| `calculated_at` | Timestamp de quando o registro foi processado/calculado. |

## ‚öôÔ∏è Tecnologias Utilizadas

| Tecnologia | Fun√ß√£o no Projeto |
| :--- | :--- |
| **Databricks** | Plataforma principal para desenvolvimento e execu√ß√£o do pipeline. |
| **Lakeflow Declarative Pipelines** | Framework declarativo para a constru√ß√£o e orquestra√ß√£o do pipeline de ETL. |
| **Apache Spark** | Motor de processamento distribu√≠do subjacente, garantindo escalabilidade. |
| **Delta Lake** | Formato de armazenamento que garante transa√ß√µes ACID e qualidade na Lakehouse. |
| **Python / SQL** | Linguagens utilizadas na defini√ß√£o das transforma√ß√µes e do pipeline. |
| **Git e GitHub** | Versionamento e controle do c√≥digo-fonte. |

## üìä Grafo do Pipeline Lakeflow

O **Lakeflow Declarative Pipelines** automatiza o fluxo de trabalho e depend√™ncias, gerando o gr√°fico de linhagem abaixo. Ele visualiza como as fontes de dados (`bronze`) se transformam, unem e progridem at√© as tabelas de consumo (`gold`), com a aplica√ß√£o de *Expectations* de qualidade em cada etapa.

A imagem se encontra no arquivo "pipeline_graph.jpg"

### Fluxo de Depend√™ncia Principal:

1.  **Ingest√£o Bronze:** M√∫ltiplas tabelas de origem (clientes, cota√ß√µes e transa√ß√µes) alimentam o pipeline.
2.  **Modelagem Silver (Dimens√µes/Fatos Intermedi√°rios):**
    * `customers` $\rightarrow$ `dim_clientes`
    * `quotation_btc` e `quotation_finance` $\rightarrow$ `fact_quotation_assets`
    * `transaction_btc` e `transaction_commodities` $\rightarrow$ `fact_transaction_assets`
    * Fatos e Dimens√µes Silver $\rightarrow$ `fact_transaction_revenue`
3.  **Camada Gold (Consumo Anal√≠tico/KPIs):**
    * Tabelas Silver $\rightarrow$ `mostvaluableclient`

## üèÅ Resultados Esperados

Ao final deste projeto, voc√™ demonstra a capacidade de:

* Configurar um ambiente Databricks completo.
* Ingerir dados de APIs com scripts Python.
* Calcular KPIs e modelar camadas **Silver** e **Gold** de acordo com requisitos de neg√≥cio.
* Aplicar boas pr√°ticas de governan√ßa e versionamento usando GitHub.
* Implementar pipelines declarativos utilizando **Lakeflow Declarative Pipelines** para automa√ß√£o e qualidade de dados.

## üîë Contato

| Email | GitHub |
| :--- | :--- |
| **rafabuenode@gmail.com** | [Bueno-00](https://github.com/Bueno-00) |
